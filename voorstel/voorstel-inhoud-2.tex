\documentclass[a4paper, 11pt]{article}

% --- Pakketten ---
\usepackage[dutch]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{a4paper, margin=2.5cm}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{parskip}

% --- Bibliografie instelling ---
\usepackage[style=apa, backend=biber]{biblatex}
\addbibresource{voorstel.bib}

% --- Document Info ---
\title{\textbf{Bachelorproefvoorstel: Big Data in Kredietanalyse}}
\author{Jouw Naam}
\date{\today}

\begin{document}

    \maketitle

    \section{Inleiding}%
    \label{sec:inleiding}
    Bij het toekennen van zakelijke leningen moeten banken en kredietverstrekkers een nauwkeurige inschatting maken van het risico op wanbetaling. Momenteel baseren analisten zich voornamelijk op de meest recente jaarrekening van de specifieke onderneming, aangevuld met externe credit scores. Deze aanpak is echter reactief en isoleert het bedrijf vaak van zijn bredere sectorale context. Het manueel vergelijken van een onderneming met al haar sectorgenoten is zonder de juiste technologische ondersteuning enorm arbeidsintensief.

    Dit onderzoek richt zich op financiële risicoanalisten en beleidsmakers binnen banken die verantwoordelijk zijn voor het bepalen van leningsvoorwaarden. De kernvraag is of de huidige methoden voldoende gebruikmaken van de enorme hoeveelheid beschikbare historische data, en of sectorbrede waarschuwingssignalen hierdoor over het hoofd worden gezien.

    \section{Probleemstelling en Bestaande Oplossingen}
    De centrale uitdaging is het verwerken van grote hoeveelheden publieke data (Open Data van de Nationale Bank van België) tot bruikbare risico-indicatoren.

    \subsection{Analyse van Bestaande Tools}
    Er is onderzoek gedaan naar bestaande softwareoplossingen die in de markt beschikbaar zijn voor financiële analyse (bijv. Belfirst, Bureau van Dijk of standaard ERP-modules).
    Hoewel deze tools krachtige rapportages bieden, hebben ze beperkingen in de context van dit onderzoek:
    \begin{itemize}
        \item \textbf{Kosten en Toegankelijkheid:} Licenties voor gespecialiseerde financiële databases zijn vaak kostbaar en gesloten.
        \item \textbf{Flexibiliteit (Black Box):} Bestaande tools geven vaak een eindscore zonder inzicht in het onderliggende algoritme. Dit onderzoek vereist juist transparantie in hoe ratio's (volgens \textcite{Ooghe2020}) worden berekend.
        \item \textbf{Machine Learning Integratie:} Standaardpakketten bieden zelden de mogelijkheid om eigen experimentele ML-modellen direct op de ruwe data te trainen.
    \end{itemize}

    \subsection{Technologiekeuze: Waarom Google BigQuery?}
    Om deze beperkingen te omzeilen, wordt gekozen voor een maatwerkoplossing in de cloud. De keuze voor Google BigQuery wordt als volgt gemotiveerd:
    \begin{itemize}
        \item \textbf{Schaalbaarheid:} BigQuery is een serverless data warehouse dat in seconden miljoenen rijen kan verwerken \parencite{GoogleCloud2024}, wat essentieel is voor de volledige NBB-dataset.
        \item \textbf{Kostenstructuur:} Het pay-as-you-go model maakt het mogelijk om zonder grote investeringen vooraf een Proof of Concept (PoC) te bouwen.
        \item \textbf{Performance:} Uit vergelijkend onderzoek blijkt dat BigQuery voor analytische queries (OLAP) vaak sneller is dan traditionele SQL-servers \parencite{Vergelijking2023}.
    \end{itemize}

    \section{Doelstelling en Onderzoeksvraag}
    De onderzoeksdoelstelling is het ontwikkelen van een Proof of Concept (PoC) waarbij de volledige dataset van de NBB (afgelopen drie jaar) wordt ingeladen in een schaalbare database.

    \textbf{Centrale onderzoeksvraag:} \\
    \textit{In welke mate kan een Big Data-architectuur op basis van publiekelijk beschikbare data bijdragen tot een nauwkeurigere financiële risico-inschatting bij kredietverlening?}

    \textbf{Deelvragen:}
    \begin{itemize}
        \item Maken huidige methoden voldoende gebruik van historische data?
        \item Kunnen sectorbrede trends en early-warning signals gedetecteerd worden die nu gemist worden?
        \item Is het mogelijk om met machine learning (BigQuery ML) ratio's te voorspellen op basis van historische NBB-data?
    \end{itemize}

    \section{Literatuurstudie}%
    \label{sec:stand-van-zaken}
    De financiële gezondheid van een onderneming wordt traditioneel geëvalueerd aan de hand van ratio-analyse (zoals liquiditeit, solvabiliteit en rentabiliteit) op basis van de jaarrekening \parencite{Ooghe2020}. Er bestaan diverse modellen, zoals de Altman Z-score, die op basis van deze ratio's faillissement trachten te voorspellen.

    Met de opkomst van 'FinTech' verschuift de focus van statische analyse naar dynamische Big Data-toepassingen. Recente literatuur toont aan dat cloud-native datawarehouses datasets enorm snel kunnen verwerken. Hierdoor wordt het mogelijk om prestaties direct af te zetten tegenover "real-time" berekende sectorgemiddelden.

    Daarnaast is er veel onderzoek naar het voorspellen van kredietrisico's via Machine Learning. Benchmarks tonen aan dat moderne technieken (zoals ensemble learning) vaak beter presteren dan traditionele statistische methoden \parencite{Lessmann2015}. Een belangrijk onderdeel van dit onderzoek is toetsen of deze algoritmen toepasbaar zijn op de specifieke structuur van de NBB-dataset.

    \section{Methodologie}%
    \label{sec:methodologie}
    Dit onderzoek volgt de methodologie van \textit{Design Science Research}, waarbij een artefact (de data-pipeline en het model) wordt gebouwd en geëvalueerd.

    Het onderzoek verloopt in vier fasen:
    \begin{enumerate}
        \item \textbf{Data Ingestie \& Engineering:} De data wordt verkregen via het Open Data portaal van de NBB. Er wordt een ETL-pipeline opgezet om deze data op te schonen en in te laden in Google BigQuery.
        \item \textbf{Segmentatie \& Benchmarking:} Ondernemingen worden geclassificeerd (o.a. op basis van NACE-codes). Er wordt onderzocht welke factoren (grootte, regio) nog meer relevant zijn voor een zinvolle segmentatie.
        \item \textbf{Validatie Bestaande Tools:} Er wordt een vergelijking gemaakt tussen de mogelijkheden van deze dataset en wat standaard beschikbaar is in de markt (gap-analyse).
        \item \textbf{Voorspellende Analyse:} Per segment wordt een experiment opgezet met BigQuery ML om op basis van de historie ($X-2$, $X-1$) financiële ratio's van jaar $X$ te voorspellen. De accuraatheid wordt getoetst via backtesting.
    \end{enumerate}

    \textbf{Tijdschatting:}
    \begin{itemize}
        \item Maand 1: Literatuurstudie, analyse bestaande tools en data-acquisitie.
        \item Maand 2-3: Opzet BigQuery en ETL-pipeline.
        \item Maand 4-5: Exploratieve analyse en segmentatie.
        \item Maand 6: Data-analyse en ontwikkeling voorspellend model.
    \end{itemize}

    \section{Verwacht Resultaat}%
    \label{sec:verwachte_resultaten}
    Het verwachte eindresultaat is een bruikbare dataset voor efficiënte financiële analyses, aangevuld met algoritmen die voorspellingen kunnen doen.

    Concreet verwacht ik:
    \begin{itemize}
        \item Een gevulde BigQuery database die performant queries uitvoert op de volledige dataset.
        \item Inzicht in sectorspecifieke trends (bijv. impact van locatie of bedrijfsgrootte op solvabiliteit).
        \item Een evaluatie van de haalbaarheid om jaarrekeningen te voorspellen: is de historische data van de NBB voldoende voorspellend?
    \end{itemize}

    De gehoopte meerwaarde is dat leningen met meer precisie toegekend kunnen worden, wat leidt tot lagere rentes voor gezonde bedrijven en risicobeheersing voor de bank.

    \newpage
    \printbibliography[title={Referenties}]

\end{document}